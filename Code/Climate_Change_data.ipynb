{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import tweepy\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json file of tweets from twitter crawler into list of dicts\n",
    "def load_json(file_name):\n",
    "    result=[]\n",
    "    with open(file_name, 'r') as fp:\n",
    "        line=fp.readline()\n",
    "        while line:\n",
    "            tjson=json.loads(line) #decode json\n",
    "            result.append({\n",
    "                \"Date\":tjson[\"created_at\"],\n",
    "                \"id\":tjson[\"id_str\"],\n",
    "                \"user_name\":tjson[\"user\"][\"name\"], \n",
    "                \"favorite_count\":tjson[\"favorite_count\"], #number of favorites\n",
    "                \"retweet_count\":tjson[\"retweet_count\"], #get number of retweets\n",
    "                \"user_id_str\":tjson[\"user\"][\"id_str\"], #get user id_str\n",
    "                \"text\":tjson[\"text\"]\n",
    "            })\n",
    "\n",
    "            line=fp.readline()\n",
    "    return result\n",
    "\n",
    "# load tweets from getoldtweets3 into list of dicts\n",
    "def load_old_json(file_name):\n",
    "    result=[]\n",
    "    with open(file_name, 'r') as fp:\n",
    "        line=fp.readline()\n",
    "        while line:\n",
    "            tjson=json.loads(line) #decode json\n",
    "            result.append({\n",
    "                \"Date\":tjson[\"Date\"],\n",
    "                \"id\":tjson[\"id\"],\n",
    "                \"favorite_count\":tjson[\"favorite_count\"], #number of favorites\n",
    "                \"retweet_count\":tjson[\"retweet_count\"], #number of retweets\n",
    "                \"text\":tjson[\"text\"]\n",
    "            })\n",
    "            line=fp.readline()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "              Date                   id  favorite_count  retweet_count  \\\n",
      "0       2020-01-22  1220134040705142789              18             17   \n",
      "1       2020-01-22  1220134028906463235               0              1   \n",
      "2       2020-01-22  1220133978046259200               3              2   \n",
      "3       2020-01-22  1220133958094151680               0              0   \n",
      "4       2020-01-22  1220133790346956800               3              0   \n",
      "...            ...                  ...             ...            ...   \n",
      "273651  2020-03-31  1244776796500955136               1              1   \n",
      "273652  2020-03-31  1244776600308195328               0              0   \n",
      "273653  2020-03-31  1244776563297488896               6              1   \n",
      "273654  2020-03-31  1244776510357151744               1              2   \n",
      "273655  2020-03-31  1244776509652586499               0              0   \n",
      "\n",
      "                                                     text  \n",
      "0       AGW GREEN WARRIORS CENSOR 1st Amendment Free S...  \n",
      "1       Urban Flooding - Rainfall hasn't increased, so...  \n",
      "2       Asm. @RobBonta introduced #AB1839, the #CAGree...  \n",
      "3       How do you like my new t-shirt? I hope the wor...  \n",
      "4       Sen. @CoryBooker: 'The U.S. won't solve #clima...  \n",
      "...                                                   ...  \n",
      "273651  Mapped: The worldâ€™s coal power plants 2020 htt...  \n",
      "273652  There are many things that we can learn from t...  \n",
      "273653  It feels pointless unfortunately. The exaspera...  \n",
      "273654  If we don't take #climatechange seriously, and...  \n",
      "273655  Should corporations be required to invest stim...  \n",
      "\n",
      "[273656 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# load tweet data\n",
    "#data_list=load_json(\"tweets.json\")\n",
    "\n",
    "#data_list=load_old_json(\"old_tweets.json\")\n",
    "filename=\"./../Data/Gatherd Data/old_tweets.json\"\n",
    "data_list=load_old_json(filename)\n",
    "# create a df\n",
    "df=pd.DataFrame(data=data_list)\n",
    "print('done')\n",
    "\n",
    "#converting date into more readable form \n",
    "Date_list= df[\"Date\"].values\n",
    "dates = []\n",
    "for date in Date_list:\n",
    "    dates.append(parse(date).date())\n",
    "df[\"Date\"]=dates\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sentiment Analysis using an VADER sentimentIntensityAnalyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "\n",
    "SIA = SentimentIntensityAnalyzer()\n",
    "#list of sentiments\n",
    "sentiments = []\n",
    "#on the basis of each text in the dataframe \n",
    "for t in df[\"text\"].values:\n",
    "    sentiment_dict = SIA.polarity_scores(t)\n",
    "    # add compound sentiment score to list \n",
    "    sentiments.append(sentiment_dict['compound']) \n",
    "# datafram column for sentiment using sentiment scores      \n",
    "df[\"sentiment\"]= sentiments\n",
    "\n",
    "#make a csv file of sentiment data (for testing purposes)\n",
    "df.to_csv(\"./../Data/Processed Data/data_with_sent.csv\", index=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id favorite_count retweet_count sentiment\n",
      "           count            sum           sum      mean\n",
      "Date                                                   \n",
      "2020-01-22  9504          49563         20441  0.233904\n",
      "2020-01-23  6427          43605         16548  0.073502\n",
      "2020-01-24  5840          46585         16407  0.091441\n",
      "2020-01-25  4194          39124         14920  0.080905\n",
      "2020-01-26  3398          16882          7865  0.064814\n",
      "...          ...            ...           ...       ...\n",
      "2020-03-29  1585           7182          4709  0.000616\n",
      "2020-03-30  2216           9481          4514  0.047642\n",
      "2020-03-31  2540          14653          7291  0.012201\n",
      "2020-04-01  2470          12600          5783  0.041370\n",
      "2020-04-02  2766          11223          5240  0.138431\n",
      "\n",
      "[72 rows x 4 columns]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# groupby date\n",
    "group=df.groupby(by=[\"Date\"])\n",
    "# find aggregate of tweet id, favorite count, retweet coint and sentiment \n",
    "new_df=group.aggregate({\n",
    "    \"id\":[\"count\"],\n",
    "    \"favorite_count\":[\"sum\"],\n",
    "    \"retweet_count\":[\"sum\"],\n",
    "    \"sentiment\":[\"mean\"]\n",
    "})\n",
    "# rename id_str to tweet_count \n",
    "new_df.rename(columns={\"id_str\":\"tweet_count\"}, inplace=True)\n",
    "\n",
    "print(new_df)\n",
    "# new csv file for old_climate data\n",
    "new_df.to_csv(\"./../Data/Processed Data/old_climate_data.csv\", index=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  total_cases  total_deaths  log_total_cases  log_total_deaths\n",
      "1   2020-01-23          654            18         2.815578          1.255273\n",
      "2   2020-01-24          941            26         2.973590          1.414973\n",
      "3   2020-01-25         1434            42         3.156549          1.623249\n",
      "4   2020-01-26         2118            56         3.325926          1.748188\n",
      "5   2020-01-27         2927            82         3.466423          1.913814\n",
      "..         ...          ...           ...              ...               ...\n",
      "67  2020-03-29       720140         33925         5.857417          4.530520\n",
      "68  2020-03-30       782389         37582         5.893423          4.574980\n",
      "69  2020-03-31       857487         42107         5.933228          4.624354\n",
      "70  2020-04-01       932605         47180         5.969698          4.673758\n",
      "71  2020-04-02      1013466         52983         6.005809          4.724137\n",
      "\n",
      "[71 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# df for cornona cases\n",
    "df_corona=pd.read_csv(\"./../Data/Processed Data/corona_data.csv\")\n",
    "\n",
    "#cut out first day becasue data is irregular and remove excess data at end\n",
    "df_corona = df_corona.iloc[1:72]\n",
    "\n",
    "#rename unnamed columns to Date\n",
    "df_corona.rename( columns={'Unnamed: 0':'Date'}, inplace=True )\n",
    "\n",
    "# convert strings to dates \n",
    "Date_list= df_corona[\"Date\"].values\n",
    "dates = []\n",
    "for date in Date_list:\n",
    "    dates.append(parse(date).date())\n",
    "df_corona[\"Date\"]=dates\n",
    "\n",
    "print(df_corona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  total_cases  total_deaths  log_total_cases  log_total_deaths  \\\n",
      "0   2020-01-23          654            18         2.815578          1.255273   \n",
      "1   2020-01-24          941            26         2.973590          1.414973   \n",
      "2   2020-01-25         1434            42         3.156549          1.623249   \n",
      "3   2020-01-26         2118            56         3.325926          1.748188   \n",
      "4   2020-01-27         2927            82         3.466423          1.913814   \n",
      "..         ...          ...           ...              ...               ...   \n",
      "66  2020-03-29       720140         33925         5.857417          4.530520   \n",
      "67  2020-03-30       782389         37582         5.893423          4.574980   \n",
      "68  2020-03-31       857487         42107         5.933228          4.624354   \n",
      "69  2020-04-01       932605         47180         5.969698          4.673758   \n",
      "70  2020-04-02      1013466         52983         6.005809          4.724137   \n",
      "\n",
      "   tweet_count favorite_count retweet_count              sentiment  \n",
      "0         6427          43605         16548    0.07350224054768949  \n",
      "1         5840          46585         16407    0.09144136986301396  \n",
      "2         4194          39124         14920    0.08090512637100558  \n",
      "3         3398          16882          7865    0.06481412595644527  \n",
      "4         4483          24535         10741    0.09473537809502562  \n",
      "..         ...            ...           ...                    ...  \n",
      "66        1585           7182          4709  0.0006164668769716072  \n",
      "67        2216           9481          4514    0.04764214801444046  \n",
      "68        2540          14653          7291   0.012201496062992112  \n",
      "69        2470          12600          5783     0.0413695546558704  \n",
      "70        2766          11223          5240     0.1384313087490966  \n",
      "\n",
      "[71 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# df for climate change tweets\n",
    "\n",
    "df_c_Change=pd.read_csv(\"./../Data/Processed Data/old_climate_data.csv\")\n",
    "# remove unwanted label cols\n",
    "df2=df_c_Change.drop([0, 1])\n",
    "# drop first day to match corona df\n",
    "df2 = df2.iloc[1:]\n",
    "# reset indexes\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "# fix date col name\n",
    "df2.rename( columns={'Unnamed: 0':'Date'}, inplace=True )\n",
    "# convert strings to dates\n",
    "Date_list= df2[\"Date\"].values\n",
    "dates = []\n",
    "for date in Date_list:\n",
    "    dates.append(parse(date).date())\n",
    "df2[\"Date\"]=dates\n",
    "\n",
    "# rename misnamed columns\n",
    "df2.rename( columns={'id':'tweet_count'}, inplace=True )\n",
    "\n",
    "# Merge both dataframes into result dataframe\n",
    "result = df_corona.merge(df2, on='Date')\n",
    "print(result)\n",
    "result.to_csv(\"./../Data/Processed Data/cleaned_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
