{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import tweepy\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json file of tweets from twitter crawler into list of dicts\n",
    "def load_json(file_name):\n",
    "    result=[]\n",
    "    with open(file_name, 'r') as fp:\n",
    "        line=fp.readline()\n",
    "        while line:\n",
    "            tjson=json.loads(line) #decode json\n",
    "            result.append({\n",
    "                \"Date\":tjson[\"created_at\"],\n",
    "                \"id\":tjson[\"id_str\"],\n",
    "                \"user_name\":tjson[\"user\"][\"name\"], \n",
    "                \"favorite_count\":tjson[\"favorite_count\"], #number of favorites\n",
    "                \"retweet_count\":tjson[\"retweet_count\"], #get number of retweets\n",
    "                \"user_id_str\":tjson[\"user\"][\"id_str\"], #get user id_str\n",
    "                \"text\":tjson[\"text\"]\n",
    "            })\n",
    "\n",
    "            line=fp.readline()\n",
    "    return result\n",
    "\n",
    "# load tweets from getoldtweets3 into list of dicts\n",
    "def load_old_json(file_name):\n",
    "    result=[]\n",
    "    with open(file_name, 'r') as fp:\n",
    "        line=fp.readline()\n",
    "        while line:\n",
    "            tjson=json.loads(line) #decode json\n",
    "            result.append({\n",
    "                \"Date\":tjson[\"Date\"],\n",
    "                \"id\":tjson[\"id\"],\n",
    "                \"favorite_count\":tjson[\"favorite_count\"], #number of favorites\n",
    "                \"retweet_count\":tjson[\"retweet_count\"], #number of retweets\n",
    "                \"text\":tjson[\"text\"]\n",
    "            })\n",
    "            line=fp.readline()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "              Date                   id  favorite_count  retweet_count  \\\n",
      "0       2020-01-22  1220134040705142789              18             17   \n",
      "1       2020-01-22  1220134028906463235               0              1   \n",
      "2       2020-01-22  1220133978046259200               3              2   \n",
      "3       2020-01-22  1220133958094151680               0              0   \n",
      "4       2020-01-22  1220133790346956800               3              0   \n",
      "...            ...                  ...             ...            ...   \n",
      "273651  2020-03-31  1244776796500955136               1              1   \n",
      "273652  2020-03-31  1244776600308195328               0              0   \n",
      "273653  2020-03-31  1244776563297488896               6              1   \n",
      "273654  2020-03-31  1244776510357151744               1              2   \n",
      "273655  2020-03-31  1244776509652586499               0              0   \n",
      "\n",
      "                                                     text  \n",
      "0       AGW GREEN WARRIORS CENSOR 1st Amendment Free S...  \n",
      "1       Urban Flooding - Rainfall hasn't increased, so...  \n",
      "2       Asm. @RobBonta introduced #AB1839, the #CAGree...  \n",
      "3       How do you like my new t-shirt? I hope the wor...  \n",
      "4       Sen. @CoryBooker: 'The U.S. won't solve #clima...  \n",
      "...                                                   ...  \n",
      "273651  Mapped: The worldâ€™s coal power plants 2020 htt...  \n",
      "273652  There are many things that we can learn from t...  \n",
      "273653  It feels pointless unfortunately. The exaspera...  \n",
      "273654  If we don't take #climatechange seriously, and...  \n",
      "273655  Should corporations be required to invest stim...  \n",
      "\n",
      "[273656 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# load tweet data\n",
    "#data_list=load_json(\"tweets.json\")\n",
    "data_list=load_old_json(\"old_tweets.json\")\n",
    "# create a df\n",
    "df=pd.DataFrame(data=data_list)\n",
    "print('done')\n",
    "\n",
    "#converting date into more readable form \n",
    "Date_list= df[\"Date\"].values\n",
    "dates = []\n",
    "for date in Date_list:\n",
    "    dates.append(parse(date).date())\n",
    "df[\"Date\"]=dates\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sentiment Analysis using an VADER sentimentIntensityAnalyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "\n",
    "SIA = SentimentIntensityAnalyzer()\n",
    "#list of sentiments\n",
    "sentiments = []\n",
    "#on the basis of each text in the dataframe \n",
    "for t in df[\"text\"].values:\n",
    "    sentiment_dict = SIA.polarity_scores(t)\n",
    "    # add compound sentiment score to list \n",
    "    sentiments.append(sentiment_dict['compound']) \n",
    "# datafram column for sentiment using sentiment scores      \n",
    "df[\"sentiment\"]= sentiments\n",
    "\n",
    "#make a csv file of sentiment data (for testing purposes)\n",
    "df.to_csv(\"data_with_sent.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id favorite_count retweet_count  sentiment\n",
      "           count            sum           sum        sum\n",
      "Date                                                    \n",
      "2020-01-22  9504          49563         20441  2223.0193\n",
      "2020-01-23  6427          43605         16548   472.3989\n",
      "2020-01-24  5840          46585         16407   534.0176\n",
      "2020-01-25  4194          39124         14920   339.3161\n",
      "2020-01-26  3398          16882          7865   220.2384\n",
      "...          ...            ...           ...        ...\n",
      "2020-03-29  1585           7182          4709     0.9771\n",
      "2020-03-30  2216           9481          4514   105.5750\n",
      "2020-03-31  2540          14653          7291    30.9918\n",
      "2020-04-01  2470          12600          5783   102.1828\n",
      "2020-04-02  2766          11223          5240   382.9010\n",
      "\n",
      "[72 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# groupby date\n",
    "group=df.groupby(by=[\"Date\"])\n",
    "# find aggregate of tweet id, favorite count, retweet coint and sentiment \n",
    "new_df=group.aggregate({\n",
    "    \"id\":[\"count\"],\n",
    "    \"favorite_count\":[\"sum\"],\n",
    "    \"retweet_count\":[\"sum\"],\n",
    "    \"sentiment\":[sum]\n",
    "})\n",
    "# rename id_str to tweet_count \n",
    "new_df.rename(columns={\"id_str\":\"tweet_count\"}, inplace=True)\n",
    "\n",
    "print(new_df)\n",
    "# new csv file for old_climate data\n",
    "new_df.to_csv(\"old_climate_data.csv\", index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
